{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_corners(img, objpoints, imgpoints, objp, window, n_rows=8, n_cols=6):\n",
    "    \"\"\"\n",
    "    get 4 corners from user clicks (in order) and use linear interpolation to get the\n",
    "    other inner points.\n",
    "    \"\"\"\n",
    "\n",
    "    order = [\"TL\", \"BL\", \"TR\", \"BR\"]\n",
    "    box_corners = []\n",
    "\n",
    "    # function to handle clicks on the image\n",
    "    def click_event(event, x, y, flags, param):\n",
    "\n",
    "        box_corners, img, window = param\n",
    "\n",
    "        # check for left mouse clicks\n",
    "        if event == cv.EVENT_LBUTTONDOWN and len(box_corners) < 4:\n",
    "\n",
    "            box_corners.append((x, y))\n",
    "\n",
    "            # display clicked points\n",
    "            # on the image window\n",
    "            font = cv.FONT_HERSHEY_SIMPLEX\n",
    "            cv.putText(\n",
    "                img, order[len(box_corners) - 1], (x, y), font, 1, (255, 0, 0), 2\n",
    "            )\n",
    "            cv.imshow(window, img)\n",
    "\n",
    "    cv.namedWindow(window, cv.WINDOW_NORMAL)\n",
    "    cv.imshow(window, img)\n",
    "    cv.setMouseCallback(window, click_event, [box_corners, img, window])\n",
    "    # wait for a key to be pressed to exit\n",
    "    # print(\"click on the 4 corners, then press any key.\")\n",
    "    cv.waitKey(0)\n",
    "\n",
    "    tl, bl, tr, br = np.array(box_corners, dtype=np.float32)\n",
    "\n",
    "    # get first and last columns of points with linear interpolation\n",
    "    first_col = np.linspace(tl, bl, n_rows)\n",
    "    last_col = np.linspace(tr, br, n_rows)\n",
    "\n",
    "    # get rest corner points by linearly interpolating the two columns\n",
    "    all_points = np.vstack(\n",
    "        [np.linspace(first_col[i], last_col[i], n_cols) for i in range(n_rows)]\n",
    "    )\n",
    "    corners = all_points.reshape(-1, 1, 2)\n",
    "\n",
    "    objpoints.append(objp)\n",
    "    imgpoints.append(corners)\n",
    "\n",
    "    cv.destroyWindow(window)\n",
    "    cv.drawChessboardCorners(img, (n_rows, n_cols), corners, True)\n",
    "    cv.imshow(\"Interpolated Chessboard Corners\", img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "def find_auto(img, gray, objpoints, imgpoints, objp, window, n_rows=9, n_cols=6):\n",
    "    \"\"\"\n",
    "    used to find the corner points and fill objpoints, imgpoints lists\n",
    "    img, gray: original and grayscale image\n",
    "    \"\"\"\n",
    "\n",
    "    # choice task - denoising\n",
    "    gray = cv.fastNlMeansDenoising(gray, None, h=10)\n",
    "\n",
    "    # detect chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (n_rows, n_cols), None)\n",
    "\n",
    "    if ret:\n",
    "        # improve quality of automatically found corners\n",
    "        criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        corners = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # display the corners on image\n",
    "        cv.drawChessboardCorners(img, (n_rows, n_cols), corners, True)\n",
    "        cv.imshow(window, img)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyWindow(window)\n",
    "    else:\n",
    "        # if corners are not found, switch to manual mode\n",
    "        click_corners(img, objpoints, imgpoints, objp, window, n_rows, n_cols)\n",
    "\n",
    "\n",
    "def flat_str(matrix, vec=False):\n",
    "\n",
    "    if vec:\n",
    "        flat = [str(element) for element in matrix.flatten().tolist()]\n",
    "    else:\n",
    "        flat = [\"  \".join(str(element) for element in row) for row in matrix.tolist()]\n",
    "    return \"\\n  \" + \"\\n  \".join(flat) + \"\\n\"\n",
    "\n",
    "\n",
    "def save_config(mtx, dist, R, tvec, video=1):\n",
    "\n",
    "    opencv_storage = ET.Element(\"opencv_storage\")\n",
    "    camera_matrix = ET.SubElement(\n",
    "        opencv_storage, \"CameraMatrix\", type_id=\"opencv-matrix\"\n",
    "    )\n",
    "    ET.SubElement(camera_matrix, \"rows\").text = \"3\"\n",
    "    ET.SubElement(camera_matrix, \"cols\").text = \"3\"\n",
    "    ET.SubElement(camera_matrix, \"dt\").text = \"f\"\n",
    "    ET.SubElement(camera_matrix, \"data\").text = flat_str(mtx)\n",
    "\n",
    "    distortion_coeffs_elem = ET.SubElement(\n",
    "        opencv_storage, \"DistortionCoeffs\", type_id=\"opencv-matrix\"\n",
    "    )\n",
    "    ET.SubElement(distortion_coeffs_elem, \"rows\").text = \"5\"\n",
    "    ET.SubElement(distortion_coeffs_elem, \"cols\").text = \"1\"\n",
    "    ET.SubElement(distortion_coeffs_elem, \"dt\").text = \"f\"\n",
    "    ET.SubElement(distortion_coeffs_elem, \"data\").text = flat_str(dist, True)\n",
    "\n",
    "    rotation_matrix_elem = ET.SubElement(\n",
    "        opencv_storage, \"RotationMatrix\", type_id=\"opencv-matrix\"\n",
    "    )\n",
    "    ET.SubElement(rotation_matrix_elem, \"rows\").text = \"3\"\n",
    "    ET.SubElement(rotation_matrix_elem, \"cols\").text = \"3\"\n",
    "    ET.SubElement(rotation_matrix_elem, \"dt\").text = \"f\"\n",
    "    ET.SubElement(rotation_matrix_elem, \"data\").text = flat_str(R)\n",
    "\n",
    "    translation_vector_elem = ET.SubElement(\n",
    "        opencv_storage, \"TranslationVector\", type_id=\"opencv-matrix\"\n",
    "    )\n",
    "    ET.SubElement(translation_vector_elem, \"rows\").text = \"3\"\n",
    "    ET.SubElement(translation_vector_elem, \"cols\").text = \"1\"\n",
    "    ET.SubElement(translation_vector_elem, \"dt\").text = \"f\"\n",
    "    ET.SubElement(translation_vector_elem, \"data\").text = flat_str(tvec, True)\n",
    "\n",
    "    camera = \"cam\" + str(video)\n",
    "    tree = ET.ElementTree(opencv_storage)\n",
    "    # write to file\n",
    "    with open(f\"data/{camera}/config.xml\", \"wb\") as file:\n",
    "        tree.write(file, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "\n",
    "def get_checkboard(video=1):\n",
    "\n",
    "    camera = \"cam\" + str(video)\n",
    "    path = f\"./data/{camera}/checkerboard.avi\"\n",
    "    cam = cv.VideoCapture(path)\n",
    "\n",
    "    if not cam.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "\n",
    "    j = 0\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cam.read()\n",
    "        if ret:\n",
    "            j += 1\n",
    "            if j == 1:\n",
    "                out_path = f\"data/{camera}/checkboard_axes.jpg\"\n",
    "                cv.imwrite(out_path, frame)\n",
    "                print(f\"Saved {out_path}\")\n",
    "            if j >= 5:\n",
    "                break\n",
    "        else:\n",
    "            print(\"failed to grab frame\")\n",
    "            break\n",
    "    cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(video=1, n_rows=8, n_cols=6):\n",
    "\n",
    "    vid = {\n",
    "        1: [1, 30, 100, 120, 160, 200],\n",
    "        2: [30, 60, 160, 400, 700, 800],\n",
    "        3: [230, 260, 280, 530, 800],\n",
    "        4: [1, 30, 60, 160, 180, 200, 260, 300],\n",
    "    }\n",
    "\n",
    "    objp = np.zeros((n_rows * n_cols, 3), np.float32)\n",
    "\n",
    "    objp[:, :2] = np.mgrid[0:n_rows, 0:n_cols].T.reshape(-1, 2)\n",
    "\n",
    "    objp = objp * 115\n",
    "\n",
    "    # Lists to store object and image points from all images.\n",
    "\n",
    "    objpoints = []  # 3d point in real world space\n",
    "\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "    for fr in vid[video]:\n",
    "\n",
    "        frame = f\"cam{video}_image{fr}.jpg\"\n",
    "\n",
    "        img = cv.imread(frame)\n",
    "\n",
    "        if img is None:\n",
    "\n",
    "            continue\n",
    "\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # we convert to grayscale before passing to 'findChessboardCorners'\n",
    "        window = frame\n",
    "        # find chess board corners either automatically or manually\n",
    "        find_auto(\n",
    "            img, gray, objpoints, imgpoints, objp, window, n_rows=n_rows, n_cols=n_cols\n",
    "        )\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(\n",
    "        objpoints, imgpoints, gray.shape[::-1], None, None\n",
    "    )\n",
    "\n",
    "    return ret, mtx, dist, rvecs, tvecs, objpoints, imgpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrinsics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_params(video=1, n_rows=8, n_cols=6):\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs, objpoints, imgpoints = calibrate(video)\n",
    "\n",
    "    # for extrinsics use checkerboard.avi\n",
    "    get_checkboard(video)\n",
    "\n",
    "    objp = np.zeros((n_rows * n_cols, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:n_rows, 0:n_cols].T.reshape(-1, 2)\n",
    "    objp = objp * 115\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "\n",
    "    camera = \"cam\" + str(video)\n",
    "    img = cv.imread(f\"data/{camera}/checkboard_axes.jpg\")\n",
    "    window = f\"extrinsic_{camera}\"\n",
    "    copy = img.copy()\n",
    "\n",
    "    click_corners(\n",
    "        img,\n",
    "        objpoints,\n",
    "        imgpoints,\n",
    "        objp,\n",
    "        window=window,\n",
    "        n_rows=n_rows,\n",
    "        n_cols=n_cols,\n",
    "    )\n",
    "\n",
    "    success, rvec, tvec = cv.solvePnP(\n",
    "        objpoints[0], imgpoints[0], mtx, dist, useExtrinsicGuess=False\n",
    "    )\n",
    "\n",
    "    if success:\n",
    "        R, _ = cv.Rodrigues(rvec)\n",
    "\n",
    "        save_config(mtx, dist, R, tvec, video)\n",
    "\n",
    "        drawn_img = drawAxes(copy, rvec, tvec, mtx, dist)\n",
    "        cv.imshow(\"3D Axes on Checkerboard\", drawn_img)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "def drawAxes(img, rvec, tvec, mtx, dist):\n",
    "\n",
    "    square = 115\n",
    "    # coordinate system\n",
    "    axis = np.float32(\n",
    "        [[0, 0, 0], [3 * square, 0, 0], [0, 3 * square, 0], [0, 0, -3 * square]]\n",
    "    )\n",
    "\n",
    "    # project the axis points and cube points to the 2D image and then convert to pixel coordinates\n",
    "    imgpts_axis, _ = cv.projectPoints(axis, rvec, tvec, mtx, dist)\n",
    "\n",
    "    origin = tuple(map(int, imgpts_axis[0].ravel()))\n",
    "    pt_x = tuple(map(int, imgpts_axis[1].ravel()))\n",
    "    pt_y = tuple(map(int, imgpts_axis[2].ravel()))\n",
    "    pt_z = tuple(map(int, imgpts_axis[3].ravel()))\n",
    "    cv.circle(img, origin, 5, (0, 255, 255), -1)\n",
    "\n",
    "    cv.arrowedLine(img, origin, pt_x, (0, 0, 255), 4, tipLength=0.2)  # X\n",
    "    cv.arrowedLine(img, origin, pt_y, (0, 255, 0), 4, tipLength=0.2)  # Y\n",
    "    cv.arrowedLine(img, origin, pt_z, (255, 0, 0), 4, tipLength=0.2)  # Z\n",
    "    cv.putText(img, \"X\", pt_x, cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv.LINE_AA)\n",
    "    cv.putText(img, \"Y\", pt_y, cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv.LINE_AA)\n",
    "    cv.putText(img, \"Z\", pt_z, cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv.LINE_AA)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/cam1/checkboard_axes.jpg\n",
      "Saved data/cam2/checkboard_axes.jpg\n",
      "Saved data/cam3/checkboard_axes.jpg\n",
      "Saved data/cam4/checkboard_axes.jpg\n"
     ]
    }
   ],
   "source": [
    "camera_params(1)\n",
    "camera_params(2)\n",
    "camera_params(3)\n",
    "camera_params(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"./data/cam2/intrinsics.avi\"\n",
    "# cam = cv.VideoCapture(path)\n",
    "\n",
    "# if not cam.isOpened():\n",
    "#     print(\"Error: Could not open video file.\")\n",
    "\n",
    "\n",
    "# j = 0\n",
    "# while True:\n",
    "\n",
    "#     ret, frame = cam.read()\n",
    "#     if ret:\n",
    "#         j += 1\n",
    "\n",
    "#         if j in [300, 400, 500, 700, 800]:\n",
    "#             # [1, 30, 60, 80, 100, 120, 160, 180, 200, 230, 260, 300]\n",
    "#             out_path = f\"cam2_image{j}.jpg\"\n",
    "#             cv.imwrite(out_path, frame)\n",
    "#             print(f\"Saved {out_path}\")\n",
    "\n",
    "#         if j >= 1000:\n",
    "#             break\n",
    "#     else:\n",
    "#         print(\"failed to grab frame\")\n",
    "#         break\n",
    "\n",
    "# cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
